{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from warnings import simplefilter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time\n",
      "duration\n",
      "radiant_win\n",
      "tower_status_radiant\n",
      "tower_status_dire\n",
      "barracks_status_radiant\n",
      "barracks_status_dire\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "data = pd.read_csv('features.csv', index_col = 'match_id')\n",
    "data_test = pd.read_csv('features_test.csv', index_col = 'match_id')\n",
    "y = data.radiant_win\n",
    "\n",
    "useless_features = ['start_time']\n",
    "for feature in data:\n",
    "    if feature not in data_test: \n",
    "        useless_features.append(feature)    \n",
    "print(*useless_features, sep = '\\n')\n",
    "\n",
    "data = data.drop(useless_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time:19553\n",
      "first_blood_team:19553\n",
      "first_blood_player1:19553\n",
      "first_blood_player2:43987\n",
      "radiant_bottle_time:15691\n",
      "radiant_courier_time:692\n",
      "radiant_flying_courier_time:27479\n",
      "radiant_first_ward_time:1836\n",
      "dire_bottle_time:16143\n",
      "dire_courier_time:676\n",
      "dire_flying_courier_time:26098\n",
      "dire_first_ward_time:1826\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "lenght = data.shape[0]\n",
    "\n",
    "for feature in data:\n",
    "    if lenght - data[feature].count() != 0:\n",
    "        print(':'.join([feature, str(lenght - data[feature].count())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "data = data.fillna(0)\n",
    "data_test = data_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radiant_win\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "print('radiant_win')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10: 0.6648506879750012: 0:00:34.280285\n",
      "20: 0.6824618768044435: 0:01:06.519922\n",
      "30: 0.6900064710388155: 0:02:04.130266\n"
     ]
    }
   ],
   "source": [
    "#5 GradiaentBoosting\n",
    "\n",
    "Kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "estimators = [10, 20, 30]\n",
    "\n",
    "X = data\n",
    "\n",
    "for n in estimators:\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    model = GradientBoostingClassifier(n_estimators = n, random_state = 42 )\n",
    "    score = cross_val_score(model, X, y, cv = Kfold, scoring = 'roc_auc').mean()\n",
    "    \n",
    "    print(n, score, datetime.now() - start_time, sep = \": \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05: 0.6951279316988187: 0:00:03.352676\n",
      "0.0001: 0.711244122262053: 0:00:05.870301\n",
      "0.001: 0.7162450543465029: 0:00:09.248632\n",
      "0.01: 0.7164357706829788: 0:00:11.214087\n",
      "0.1: 0.7164100547748318: 0:00:11.271984\n",
      "1.0: 0.7164079384372608: 0:00:12.613465\n",
      "10.0: 0.7164073770138559: 0:00:16.065362\n",
      "100.0: 0.7164072520277948: 0:00:13.187008\n",
      "1000.0: 0.7164072372000616: 0:00:11.348722\n",
      "10000.0: 0.7164072266072526: 0:00:11.644851\n",
      "100000.0: 0.7164072266072526: 0:00:11.614683\n"
     ]
    }
   ],
   "source": [
    "#1 LogisticRegression\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "Kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "for i in range(-5, 6):\n",
    "    C = 10.0 ** i\n",
    "    \n",
    "    model = LogisticRegression(C = C, random_state = 42)\n",
    "    start_time = datetime.now()\n",
    "    score = cross_val_score(model, X_train, y, cv = Kfold, scoring = 'roc_auc').mean()\n",
    "    print(C, score, datetime.now() - start_time, sep = ': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05: 0.695064532999037: 0:00:02.838029\n",
      "0.0001: 0.7112201334097993: 0:00:04.711490\n",
      "0.001: 0.7162550133772639: 0:00:07.665262\n",
      "0.01: 0.7164424484366461: 0:00:10.395201\n",
      "0.1: 0.7164166513037841: 0:00:11.125501\n",
      "1.0: 0.7164140413807418: 0:00:11.184084\n",
      "10.0: 0.7164137680368765: 0:00:10.683429\n",
      "100.0: 0.7164137341365804: 0:00:10.753232\n",
      "1000.0: 0.7164137298947635: 0:00:10.566517\n",
      "10000.0: 0.7164137362495984: 0:00:11.255086\n",
      "100000.0: 0.7164137362495984: 0:00:10.855950\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "categorial_features = ['lobby_type', 'r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']\n",
    "\n",
    "X = data.drop(categorial_features, axis = 1)\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "for i in range(-5, 6):\n",
    "    C = 10.0 ** i\n",
    "    \n",
    "    model = LogisticRegression(C = C, random_state = 42)\n",
    "    start_time = datetime.now()\n",
    "    score = cross_val_score(model, X_train, y, cv = Kfold, scoring = 'roc_auc').mean()\n",
    "    \n",
    "    print(C, score, datetime.now() - start_time, sep = ': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 уникальных героев\n"
     ]
    }
   ],
   "source": [
    "#3 \n",
    "unique_heroes = pd.unique(data[['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']].values.ravel())\n",
    "N = max(unique_heroes)\n",
    "print(len(unique_heroes), 'уникальных героев')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 \n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "X_pick = pd.DataFrame(X_pick, index = data.index, columns = [f'hero_{i}' for i in range(N)])\n",
    "X = pd.concat([X, X_pick], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-05: 0.7177854597962655: 0:00:57.009688\n",
      "0.0001: 0.7283867631881902: 0:01:46.187295\n",
      "0.001: 0.7459061442504172: 0:03:01.618360\n",
      "0.01: 0.7515231350137639: 0:04:23.855758\n",
      "0.1: 0.751791646013773: 0:04:28.558336\n",
      "1.0: 0.7517460096439752: 0:03:59.938228\n",
      "10.0: 0.7517160423022433: 0:04:34.982120\n",
      "100.0: 0.7517749279713775: 0:03:54.751677\n",
      "1000.0: 0.7517151961669672: 0:04:24.191843\n",
      "10000.0: 0.7517603492213729: 0:04:16.597228\n",
      "100000.0: 0.751750060653966: 0:03:59.722225\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "for i in range(-5, 6):\n",
    "    C = 10.0 ** i\n",
    "    \n",
    "    model = LogisticRegression(C = C, random_state = 42)\n",
    "    start_time = datetime.now()\n",
    "    score = cross_val_score(model, X, y, cv = Kfold, scoring = 'roc_auc').mean()\n",
    "    \n",
    "    print(C, score, datetime.now() - start_time, sep = ': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/wwberry/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing test data\n",
    "X_test = data_test\n",
    "X_test = X_test.drop('start_time', axis = 1)\n",
    "X_test = X_test.drop(categorial_features, axis = 1)\n",
    "\n",
    "unique_heroes = pd.unique(data_test[['r1_hero', 'r2_hero', 'r3_hero', 'r4_hero', 'r5_hero',\n",
    "                      'd1_hero', 'd2_hero', 'd3_hero', 'd4_hero', 'd5_hero']].values.ravel())\n",
    "N = max(unique_heroes)\n",
    "\n",
    "X_pick = np.zeros((data_test.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data_test.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data_test.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data_test.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "X_pick = pd.DataFrame(X_pick, index = data_test.index, columns = [f'hero_{i}' for i in range(N)])\n",
    "X_test = pd.concat([X_test, X_pick], axis = 1)\n",
    "\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    17177.000000\n",
       "mean         0.500382\n",
       "std          0.303883\n",
       "min          0.000046\n",
       "25%          0.229049\n",
       "50%          0.499540\n",
       "75%          0.770704\n",
       "max          0.999923\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "model = LogisticRegression(C = 0.1, random_state = 42)\n",
    "model.fit(X, y)\n",
    "\n",
    "preds = pd.Series(model.predict_proba(X_test)[:, 1])\n",
    "preds.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some extra possible preprocessing\n",
    "\n",
    "data = pd.read_csv('features.csv', index_col = 'match_id')\n",
    "data_test = pd.read_csv('features_test.csv', index_col = 'match_id')\n",
    "\n",
    "#Possible Preprocessing test\n",
    "\n",
    "data_test.d1_kills = data_test.d1_kills + data_test.d2_kills + data_test.d3_kills + data_test.d4_kills + data_test.d5_kills\n",
    "data_test.r1_kills = data_test.r1_kills + data_test.r2_kills + data_test.r3_kills + data_test.r4_kills + data_test.r5_kills\n",
    "\n",
    "data_test.r1_lh = data_test.r1_lh + data_test.r2_lh + data_test.r3_lh + data_test.r4_lh + data_test.r5_lh\n",
    "data_test.d2_lh = data_test.d1_lh + data_test.d2_lh + data_test.d3_lh + data_test.d4_lh + data_test.d5_lh\n",
    "\n",
    "\n",
    "data_test.radiant_boots_count = data_test.radiant_boots_count + data_test.radiant_tpscroll_count + data_test.radiant_ward_observer_count + data_test.radiant_ward_sentry_count\n",
    "data_test.dire_boots_count = data_test.dire_boots_count + data_test.dire_tpscroll_count + data_test.dire_ward_observer_count + data_test.dire_ward_sentry_count\n",
    "\n",
    "useless_features = ['start_time', 'lobby_type', 'first_blood_player1', 'first_blood_player2', 'd2_kills', 'd3_kills', 'd4_kills', 'd5_kills', 'd2_lh', 'd3_lh', 'd4_lh', 'd5_lh', 'r2_kills', 'r3_kills', 'r4_kills', 'r5_kills', 'r2_lh', 'r3_lh', 'r4_lh', 'r5_lh',\n",
    "                   'radiant_tpscroll_count', 'radiant_ward_observer_count', 'radiant_ward_sentry_count', 'dire_tpscroll_count', 'dire_ward_observer_count', 'dire_ward_sentry_count']\n",
    "\n",
    "#train\n",
    "\n",
    "\n",
    "data.d1_kills = data.d1_kills + data.d2_kills + data.d3_kills + data.d4_kills + data.d5_kills\n",
    "data.r1_kills = data.r1_kills + data.r2_kills + data.r3_kills + data.r4_kills + data.r5_kills\n",
    "\n",
    "data.r1_lh = data.r1_lh + data.r2_lh + data.r3_lh + data.r4_lh + data.r5_lh\n",
    "data.d2_lh = data.d1_lh + data.d2_lh + data.d3_lh + data.d4_lh + data.d5_lh\n",
    "\n",
    "\n",
    "data.radiant_boots_count = data.radiant_boots_count + data.radiant_tpscroll_count + data.radiant_ward_observer_count + data.radiant_ward_sentry_count\n",
    "data.dire_boots_count = data.dire_boots_count + data.dire_tpscroll_count + data.dire_ward_observer_count + data.dire_ward_sentry_count\n",
    "\n",
    "useless_features = ['start_time', 'lobby_type', 'first_blood_player1', 'first_blood_player2', 'd2_kills', 'd3_kills', 'd4_kills', 'd5_kills', 'd2_lh', 'd3_lh', 'd4_lh', 'd5_lh', 'r2_kills', 'r3_kills', 'r4_kills', 'r5_kills', 'r2_lh', 'r3_lh', 'r4_lh', 'r5_lh',\n",
    "                   'radiant_tpscroll_count', 'radiant_ward_observer_count', 'radiant_ward_sentry_count', 'dire_tpscroll_count', 'dire_ward_observer_count', 'dire_ward_sentry_count']\n",
    "for feature in data:\n",
    "    if feature not in data_test:\n",
    "        useless_features.append(feature)\n",
    "\n",
    "y = data.radiant_win\n",
    "X = data.drop(useless_features, axis = 1)\n",
    "X_test = data_test.drop(useless_features, axis = 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
